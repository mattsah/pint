/**
 * LR parser for C++ generated by the Syntax tool.
 *
 * https://www.npmjs.com/package/syntax-cli
 *
 *   npm install -g syntax-cli
 *
 *   syntax-cli --help
 *
 * To regenerate run:
 *
 *   syntax-cli \
 *     --grammar ~/path-to-grammar-file \
 *     --mode <parsing-mode> \
 *     --output ~/ParserClassName.h
 */
#ifndef __Syntax_LR_Parser_h
#define __Syntax_LR_Parser_h

#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wunused-private-field"

#include <assert.h>
#include <array>
#include <iostream>
#include <map>
#include <memory>
#include <regex>
#include <sstream>
#include <string>
#include <vector>

// ------------------------------------
// Module include prologue.
//
// Should include at least value/result type:
//
// type Value = <...>;
//
// Or struct Value { ... };
//
// Can also include parsing hooks:
//
//   void onParseBegin(const Parser& parser, const std::string& str) {
//     ...
//   }
//
//   void onParseBegin(const Parser& parser, const Value& result) {
//     ...
//   }
//
// clang-format off
#include "tree.h"

  using namespace pint;
  using Value = std::shared_ptr<Node>;

  
  #define debug(msg) std::cout <<  std::string(2 * (parser.valuesStack.size() - 1), ' ') << msg << std::endl;
  // #define debug(msg)  // clang-format on

namespace syntax {

/**
 * Tokenizer class.
 */
// clang-format off
/**
 * Generic tokenizer used by the parser in the Syntax tool.
 *
 * https://www.npmjs.com/package/syntax-cli
 */

#ifndef __Syntax_Tokenizer_h
#define __Syntax_Tokenizer_h

class Tokenizer;

// ------------------------------------------------------------------
// TokenType.

enum class TokenType {
  __EMPTY = -1,
  // clang-format off
  SEMICOLON = 38,
  REAL = 39,
  INTEGER = 40,
  BOOLEAN = 41,
  STRING = 42,
  IDENTIFIER = 43,
  SEPARATOR = 44,
  TYPE_BASE = 45,
  TYPE_FORM = 46,
  TYPE_TMPL = 47,
  TOKEN_TYPE_48 = 48,
  TOKEN_TYPE_49 = 49,
  TOKEN_TYPE_50 = 50,
  TOKEN_TYPE_51 = 51,
  TOKEN_TYPE_52 = 52,
  TOKEN_TYPE_53 = 53,
  TOKEN_TYPE_54 = 54,
  TOKEN_TYPE_55 = 55,
  TOKEN_TYPE_56 = 56,
  TOKEN_TYPE_57 = 57,
  TOKEN_TYPE_58 = 58,
  TOKEN_TYPE_59 = 59,
  TOKEN_TYPE_60 = 60,
  TOKEN_TYPE_61 = 61,
  TOKEN_TYPE_62 = 62,
  TOKEN_TYPE_63 = 63,
  TOKEN_TYPE_64 = 64,
  TOKEN_TYPE_65 = 65,
  __EOF = 66
  // clang-format on
};

// ------------------------------------------------------------------
// Token.

struct Token {
  TokenType type;
  std::string value;

  int startOffset;
  int endOffset;
  int startLine;
  int endLine;
  int startColumn;
  int endColumn;
};

using SharedToken = std::shared_ptr<Token>;

typedef TokenType (*LexRuleHandler)(const Tokenizer&, const std::string&);

// ------------------------------------------------------------------
// Lex rule: [regex, handler]

struct LexRule {
  std::regex regex;
  LexRuleHandler handler;
};

// ------------------------------------------------------------------
// Token.

enum TokenizerState {
  // clang-format off
  INITIAL
  // clang-format on
};

// ------------------------------------------------------------------
// Tokenizer.

class Tokenizer {
 public:
  /**
   * Initializes a parsing string.
   */
  void initString(const std::string& str) {
    str_ = str;

    // Initialize states.
    states_.clear();
    states_.push_back(TokenizerState::INITIAL);

    cursor_ = 0;
    currentLine_ = 1;
    currentColumn_ = 0;
    currentLineBeginOffset_ = 0;

    tokenStartOffset_ = 0;
    tokenEndOffset_ = 0;
    tokenStartLine_ = 0;
    tokenEndLine_ = 0;
    tokenStartColumn_ = 0;
    tokenEndColumn_ = 0;
  }

  /**
   * Whether there are still tokens in the stream.
   */
  inline bool hasMoreTokens() { return cursor_ <= str_.length(); }

  /**
   * Returns current tokenizing state.
   */
  TokenizerState getCurrentState() { return states_.back(); }

  /**
   * Enters a new state pushing it on the states stack.
   */
  void pushState(TokenizerState state) { states_.push_back(state); }

  /**
   * Alias for `push_state`.
   */
  void begin(TokenizerState state) { states_.push_back(state); }

  /**
   * Exits a current state popping it from the states stack.
   */
  TokenizerState popState() {
    auto state = states_.back();
    states_.pop_back();
    return state;
  }

  /**
   * Returns next token.
   */
  SharedToken getNextToken() {
    if (!hasMoreTokens()) {
      yytext = __EOF;
      return toToken(TokenType::__EOF);
    }

    auto strSlice = str_.substr(cursor_);

    auto lexRulesForState = lexRulesByStartConditions_.at(getCurrentState());

    for (const auto& ruleIndex : lexRulesForState) {
      auto rule = lexRules_[ruleIndex];
      std::smatch sm;

      if (std::regex_search(strSlice, sm, rule.regex)) {
        yytext = sm[0];

        captureLocations_(yytext);
        cursor_ += yytext.length();

        // Manual handling of EOF token (the end of string). Return it
        // as `EOF` symbol.
        if (yytext.length() == 0) {
          cursor_++;
        }

        auto tokenType = rule.handler(*this, yytext);

        if (tokenType == TokenType::__EMPTY) {
          return getNextToken();
        }

        return toToken(tokenType);
      }
    }

    if (isEOF()) {
      cursor_++;
      yytext = __EOF;
      return toToken(TokenType::__EOF);
    }

    throwUnexpectedToken(std::string(1, strSlice[0]), currentLine_,
                         currentColumn_);
  }

  /**
   * Whether the cursor is at the EOF.
   */
  inline bool isEOF() { return cursor_ == str_.length(); }

  SharedToken toToken(TokenType tokenType) {
    return std::shared_ptr<Token>(new Token{
        .type = tokenType,
        .value = yytext,
        .startOffset = tokenStartOffset_,
        .endOffset = tokenEndOffset_,
        .startLine = tokenStartLine_,
        .endLine = tokenEndLine_,
        .startColumn = tokenStartColumn_,
        .endColumn = tokenEndColumn_,
    });
  }

  /**
   * Throws default "Unexpected token" exception, showing the actual
   * line from the source, pointing with the ^ marker to the bad token.
   * In addition, shows `line:column` location.
   */
  [[noreturn]] void throwUnexpectedToken(const std::string& symbol, int line,
                                         int column) {
    std::stringstream ss{str_};
    std::string lineStr;
    int currentLine = 1;

    while (currentLine++ <= line) {
      std::getline(ss, lineStr, '\n');
    }

    auto pad = std::string(column, ' ');

    std::stringstream errMsg;

    errMsg << "Syntax Error:\n\n"
           << lineStr << "\n"
           << pad << "^\nUnexpected token \"" << symbol << "\" at " << line
           << ":" << column << "\n\n";

    std::cerr << errMsg.str();
    throw new std::runtime_error(errMsg.str().c_str());
  }

  /**
   * Matched text.
   */
  std::string yytext;

 private:
  /**
   * Captures token locations.
   */
  void captureLocations_(const std::string& matched) {
    auto len = matched.length();

    // Absolute offsets.
    tokenStartOffset_ = cursor_;

    // Line-based locations, start.
    tokenStartLine_ = currentLine_;
    tokenStartColumn_ = tokenStartOffset_ - currentLineBeginOffset_;

    // Extract `\n` in the matched token.
    std::stringstream ss{matched};
    std::string lineStr;
    std::getline(ss, lineStr, '\n');
    while (ss.tellg() > 0 && ss.tellg() <= len) {
      currentLine_++;
      currentLineBeginOffset_ = tokenStartOffset_ + ss.tellg();
      std::getline(ss, lineStr, '\n');
    }

    tokenEndOffset_ = cursor_ + len;

    // Line-based locations, end.
    tokenEndLine_ = currentLine_;
    tokenEndColumn_ = tokenEndOffset_ - currentLineBeginOffset_;
    currentColumn_ = tokenEndColumn_;
  }

  /**
   * Lexical rules.
   */
  // clang-format off
  static constexpr size_t LEX_RULES_COUNT = 31;
  static std::array<LexRule, LEX_RULES_COUNT> lexRules_;
  static std::map<TokenizerState, std::vector<size_t>> lexRulesByStartConditions_;
  // clang-format on

  /**
   * Special EOF token.
   */
  static std::string __EOF;

  /**
   * Tokenizing string.
   */
  std::string str_;

  /**
   * Cursor for current symbol.
   */
  int cursor_;

  /**
   * States.
   */
  std::vector<TokenizerState> states_;

  /**
   * Line-based location tracking.
   */
  int currentLine_;
  int currentColumn_;
  int currentLineBeginOffset_;

  /**
   * Location data of a matched token.
   */
  int tokenStartOffset_;
  int tokenEndOffset_;
  int tokenStartLine_;
  int tokenEndLine_;
  int tokenStartColumn_;
  int tokenEndColumn_;
};

// ------------------------------------------------------------------
// Lexical rule handlers.

std::string Tokenizer::__EOF("$");

// clang-format off
inline TokenType _lexRule1(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::TOKEN_TYPE_48;
}

inline TokenType _lexRule2(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::TOKEN_TYPE_49;
}

inline TokenType _lexRule3(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::TOKEN_TYPE_50;
}

inline TokenType _lexRule4(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::TOKEN_TYPE_51;
}

inline TokenType _lexRule5(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::TOKEN_TYPE_52;
}

inline TokenType _lexRule6(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::TOKEN_TYPE_53;
}

inline TokenType _lexRule7(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::TOKEN_TYPE_54;
}

inline TokenType _lexRule8(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::TOKEN_TYPE_55;
}

inline TokenType _lexRule9(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::TOKEN_TYPE_56;
}

inline TokenType _lexRule10(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::TOKEN_TYPE_57;
}

inline TokenType _lexRule11(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::TOKEN_TYPE_58;
}

inline TokenType _lexRule12(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::TOKEN_TYPE_59;
}

inline TokenType _lexRule13(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::TOKEN_TYPE_60;
}

inline TokenType _lexRule14(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::TOKEN_TYPE_61;
}

inline TokenType _lexRule15(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::TOKEN_TYPE_62;
}

inline TokenType _lexRule16(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::TOKEN_TYPE_63;
}

inline TokenType _lexRule17(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::TOKEN_TYPE_64;
}

inline TokenType _lexRule18(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::TOKEN_TYPE_65;
}

inline TokenType _lexRule19(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::__EMPTY;
}

inline TokenType _lexRule20(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::__EMPTY;
}

inline TokenType _lexRule21(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::__EMPTY;
}

inline TokenType _lexRule22(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::TYPE_BASE;
}

inline TokenType _lexRule23(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::TYPE_FORM;
}

inline TokenType _lexRule24(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::TYPE_TMPL;
}

inline TokenType _lexRule25(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::STRING;
}

inline TokenType _lexRule26(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::BOOLEAN;
}

inline TokenType _lexRule27(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::REAL;
}

inline TokenType _lexRule28(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::INTEGER;
}

inline TokenType _lexRule29(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::IDENTIFIER;
}

inline TokenType _lexRule30(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::SEMICOLON;
}

inline TokenType _lexRule31(const Tokenizer& tokenizer, const std::string& yytext) {
return TokenType::SEPARATOR;
}
// clang-format on

// ------------------------------------------------------------------
// Lexical rules.

// clang-format off
std::array<LexRule, Tokenizer::LEX_RULES_COUNT> Tokenizer::lexRules_ = {{
  {std::regex(R"(^\.)"), &_lexRule1},
  {std::regex(R"(^,)"), &_lexRule2},
  {std::regex(R"(^unit)"), &_lexRule3},
  {std::regex(R"(^uses)"), &_lexRule4},
  {std::regex(R"(^as)"), &_lexRule5},
  {std::regex(R"(^\()"), &_lexRule6},
  {std::regex(R"(^\))"), &_lexRule7},
  {std::regex(R"(^register)"), &_lexRule8},
  {std::regex(R"(^:)"), &_lexRule9},
  {std::regex(R"(^=)"), &_lexRule10},
  {std::regex(R"(^begin)"), &_lexRule11},
  {std::regex(R"(^end)"), &_lexRule12},
  {std::regex(R"(^\[)"), &_lexRule13},
  {std::regex(R"(^\])"), &_lexRule14},
  {std::regex(R"(^var)"), &_lexRule15},
  {std::regex(R"(^function)"), &_lexRule16},
  {std::regex(R"(^constructor)"), &_lexRule17},
  {std::regex(R"(^void)"), &_lexRule18},
  {std::regex(R"(^\s+)"), &_lexRule19},
  {std::regex(R"(^\{[^\}]*\})"), &_lexRule20},
  {std::regex(R"(^\/\/.*\n)"), &_lexRule21},
  {std::regex(R"(^(integer|cardinal|real|char|string|boolean))"), &_lexRule22},
  {std::regex(R"(^(interface|implementation|class))"), &_lexRule23},
  {std::regex(R"(^(type|label|record))"), &_lexRule24},
  {std::regex(R"(^(['"])(.*?[^\\])?(\\\\)*(\1))"), &_lexRule25},
  {std::regex(R"(^true|false)"), &_lexRule26},
  {std::regex(R"(^[0-9]+\.[0-9]+)"), &_lexRule27},
  {std::regex(R"(^[0-9]+)"), &_lexRule28},
  {std::regex(R"(^[a-zA-Z_][a-zA-Z0-9_]*)"), &_lexRule29},
  {std::regex(R"(^[;])"), &_lexRule30},
  {std::regex(R"(^\\)"), &_lexRule31}
}};
std::map<TokenizerState, std::vector<size_t>> Tokenizer::lexRulesByStartConditions_ =  {{TokenizerState::INITIAL, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30}}};
// clang-format on

#endif
// clang-format on

#define POP_V()              \
  parser.valuesStack.back(); \
  parser.valuesStack.pop_back()

#define POP_T()              \
  parser.tokensStack.back(); \
  parser.tokensStack.pop_back()

#define PUSH_VR() parser.valuesStack.push_back(__)
#define PUSH_TR() parser.tokensStack.push_back(__)

/**
 * Parsing table type.
 */
enum class TE {
  Accept,
  Shift,
  Reduce,
  Transit,
};

/**
 * Parsing table entry.
 */
struct TableEntry {
  TE type;
  int value;
};

// clang-format off
class parser;
// clang-format on

using yyparse = parser;

typedef void (*ProductionHandler)(yyparse&);

/**
 * Encoded production.
 *
 * opcode - encoded index
 * rhsLength - length of the RHS to pop.
 */
struct Production {
  int opcode;
  int rhsLength;
  ProductionHandler handler;
};

// Key: Encoded symbol (terminal or non-terminal) index
// Value: TableEntry
using Row = std::map<int, TableEntry>;

/**
 * Parser class.
 */
// clang-format off
class parser {
  // clang-format on
 public:
  /**
   * Parsing values stack.
   */
  std::vector<Value> valuesStack;

  /**
   * Token values stack.
   */
  std::vector<std::string> tokensStack;

  /**
   * Parsing states stack.
   */
  std::vector<int> statesStack;

  /**
   * Tokenizer.
   */
  Tokenizer tokenizer;

  /**
   * Previous state to calculate the next one.
   */
  int previousState;

  /**
   * Parses a string.
   */
  Value parse(const std::string& str) {
    // clang-format off
    
    // clang-format on

    // Initialize the tokenizer and the string.
    tokenizer.initString(str);

    // Initialize the stacks.
    valuesStack.clear();
    tokensStack.clear();
    statesStack.clear();

    // Initial 0 state.
    statesStack.push_back(0);

    auto token = tokenizer.getNextToken();
    auto shiftedToken = token;

    // Main parsing loop.
    for (;;) {
      auto state = statesStack.back();
      auto column = (int)token->type;

      if (table_[state].count(column) == 0) {
        throwUnexpectedToken(token);
      }

      auto entry = table_[state].at(column);

      // Shift a token, go to state.
      if (entry.type == TE::Shift) {
        // Push token.
        tokensStack.push_back(token->value);

        // Push next state number: "s5" -> 5
        statesStack.push_back(entry.value);

        shiftedToken = token;
        token = tokenizer.getNextToken();
      }

      // Reduce by production.
      else if (entry.type == TE::Reduce) {
        auto productionNumber = entry.value;
        auto production = productions_[productionNumber];

        tokenizer.yytext = shiftedToken->value;

        auto rhsLength = production.rhsLength;
        while (rhsLength > 0) {
          statesStack.pop_back();
          rhsLength--;
        }

        // Call the handler.
        production.handler(*this);

        auto previousState = statesStack.back();

        auto symbolToReduceWith = production.opcode;
        auto nextStateEntry = table_[previousState].at(symbolToReduceWith);
        assert(nextStateEntry.type == TE::Transit);

        statesStack.push_back(nextStateEntry.value);
      }

      // Accept the string.
      else if (entry.type == TE::Accept) {
        // Pop state number.
        statesStack.pop_back();

        // Pop the parsed value.
        // clang-format off
        auto result = valuesStack.back(); valuesStack.pop_back();
        // clang-format on

        if (statesStack.size() != 1 || statesStack.back() != 0 ||
            tokenizer.hasMoreTokens()) {
          throwUnexpectedToken(token);
        }

        statesStack.pop_back();

        // clang-format off
        
        // clang-format on

        return result;
      }
    }
  }

 private:
  /**
   * Throws parser error on unexpected token.
   */
  [[noreturn]] void throwUnexpectedToken(SharedToken token) {
    if (token->type == TokenType::__EOF && !tokenizer.hasMoreTokens()) {
      std::string errMsg = "Unexpected end of input.\n";
      std::cerr << errMsg;
      throw std::runtime_error(errMsg.c_str());
    }
    tokenizer.throwUnexpectedToken(token->value, token->startLine,
                                   token->startColumn);
  }

  // clang-format off
  static constexpr size_t PRODUCTIONS_COUNT = 79;
  static std::array<Production, PRODUCTIONS_COUNT> productions_;

  static constexpr size_t ROWS_COUNT = 125;
  static std::array<Row, ROWS_COUNT> table_;
  // clang-format on
};

// ------------------------------------------------------------------
// Productions.

// clang-format off
void _handler1(yyparse& parser) {
// Semantic action prologue.
auto _1 = POP_V();

auto __ = _1;

 // Semantic action epilogue.
PUSH_VR();

}

void _handler2(yyparse& parser) {
// Semantic action prologue.


auto __ = std::make_shared<ListNode>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler3(yyparse& parser) {
// Semantic action prologue.
auto _2 = POP_V();
auto _1 = POP_V();

as(ListNode, _1)->list.push_back(_2);
    auto __ = _1;

 // Semantic action epilogue.
PUSH_VR();

}

void _handler4(yyparse& parser) {
// Semantic action prologue.
auto _1 = POP_V();

debug("code_line: unit" << std::endl);
    auto __ = _1;

 // Semantic action epilogue.
PUSH_VR();

}

void _handler5(yyparse& parser) {
// Semantic action prologue.
auto _1 = POP_V();

debug("code_line: uses" << std::endl);
    auto __ = _1;

 // Semantic action epilogue.
PUSH_VR();

}

void _handler6(yyparse& parser) {
// Semantic action prologue.
auto _1 = POP_V();

debug("code_line: register" << std::endl);
    auto __ = _1;

 // Semantic action epilogue.
PUSH_VR();

}

void _handler7(yyparse& parser) {
// Semantic action prologue.


debug("body: empty");
    auto __ = std::make_shared<ListNode>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler8(yyparse& parser) {
// Semantic action prologue.
auto _2 = POP_V();
auto _1 = POP_V();

debug("body: body body_line");
    as(ListNode, _1)->list.push_back(_2);
    auto __ = _1;

 // Semantic action epilogue.
PUSH_VR();

}

void _handler9(yyparse& parser) {
// Semantic action prologue.
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();

debug("body_line: expr;");
    auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler10(yyparse& parser) {
// Semantic action prologue.
parser.valuesStack.pop_back();

auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler11(yyparse& parser) {
// Semantic action prologue.
auto _1 = POP_T();

debug("literal: " + _1);
    auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler12(yyparse& parser) {
// Semantic action prologue.
auto _1 = POP_T();

debug("literal: " + _1);
    auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler13(yyparse& parser) {
// Semantic action prologue.
auto _1 = POP_T();

debug("literal: " + _1);
    auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler14(yyparse& parser) {
// Semantic action prologue.
auto _1 = POP_T();

debug("literal: " + _1);
    auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler15(yyparse& parser) {
// Semantic action prologue.
auto _1 = POP_T();

debug("identifier: IDENTIFIER(" + _1 + ")");
    auto __ = std::make_shared<IdentifierNode>(_1);

 // Semantic action epilogue.
PUSH_VR();

}

void _handler16(yyparse& parser) {
// Semantic action prologue.
auto _1 = POP_V();

debug("path: identifier");
    auto __ = std::make_shared<ListNode>(_1);

 // Semantic action epilogue.
PUSH_VR();

}

void _handler17(yyparse& parser) {
// Semantic action prologue.
auto _3 = POP_V();
parser.tokensStack.pop_back();
auto _1 = POP_V();

debug("path: path\\identifier");
    as(ListNode, _1)->list.push_back(_3);
    auto __ = _1;

 // Semantic action epilogue.
PUSH_VR();

}

void _handler18(yyparse& parser) {
// Semantic action prologue.
parser.valuesStack.pop_back();

auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler19(yyparse& parser) {
// Semantic action prologue.
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();

auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler20(yyparse& parser) {
// Semantic action prologue.
auto _1 = POP_V();

auto __ = std::make_shared<ListNode>(_1);

 // Semantic action epilogue.
PUSH_VR();

}

void _handler21(yyparse& parser) {
// Semantic action prologue.
auto _3 = POP_V();
parser.tokensStack.pop_back();
auto _1 = POP_V();

as(ListNode, _1)->list.push_back(_3);
    auto __ = _1;

 // Semantic action epilogue.
PUSH_VR();

}

void _handler22(yyparse& parser) {
// Semantic action prologue.
parser.tokensStack.pop_back();
auto _2 = POP_V();
parser.tokensStack.pop_back();

debug("unit: unit identifier;");
    auto __ = std::make_shared<UnitNode>(std::make_shared<ListNode>(_2));

 // Semantic action epilogue.
PUSH_VR();

}

void _handler23(yyparse& parser) {
// Semantic action prologue.
auto _4 = POP_V();
parser.tokensStack.pop_back();
auto _2 = POP_V();
parser.tokensStack.pop_back();

debug("unit: unit path\\identifier;");
    as(ListNode, _2)->list.push_back(_4);
    auto __ = std::make_shared<UnitNode>(as(ListNode, _2));

 // Semantic action epilogue.
PUSH_VR();

}

void _handler24(yyparse& parser) {
// Semantic action prologue.
parser.tokensStack.pop_back();
auto _2 = POP_V();
parser.tokensStack.pop_back();

debug("uses: import_list;")
    auto __ = std::make_shared<UsesNode>(as(ListNode, _2));

 // Semantic action epilogue.
PUSH_VR();

}

void _handler25(yyparse& parser) {
// Semantic action prologue.
auto _1 = POP_V();

auto __ = std::make_shared<ListNode>(_1);

 // Semantic action epilogue.
PUSH_VR();

}

void _handler26(yyparse& parser) {
// Semantic action prologue.
auto _3 = POP_V();
parser.tokensStack.pop_back();
auto _1 = POP_V();

as(ListNode, _1)->list.push_back(_3);
    auto __ = _1;

 // Semantic action epilogue.
PUSH_VR();

}

void _handler27(yyparse& parser) {
// Semantic action prologue.
parser.valuesStack.pop_back();

auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler28(yyparse& parser) {
// Semantic action prologue.
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();

auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler29(yyparse& parser) {
// Semantic action prologue.
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();

auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler30(yyparse& parser) {
// Semantic action prologue.
auto _1 = POP_V();

auto __ = std::make_shared<ListNode>(_1);

 // Semantic action epilogue.
PUSH_VR();

}

void _handler31(yyparse& parser) {
// Semantic action prologue.
auto _3 = POP_V();
parser.tokensStack.pop_back();
auto _1 = POP_V();

as(ListNode, _1)->list.push_back(_3);
    auto __ = _1;

 // Semantic action epilogue.
PUSH_VR();

}

void _handler32(yyparse& parser) {
// Semantic action prologue.
parser.valuesStack.pop_back();

auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler33(yyparse& parser) {
// Semantic action prologue.
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();

auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler34(yyparse& parser) {
// Semantic action prologue.
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();

auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler35(yyparse& parser) {
// Semantic action prologue.
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();

// register: function =
    auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler36(yyparse& parser) {
// Semantic action prologue.
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();

debug("register: register identifier: type_func_decl begin body end");
    auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler37(yyparse& parser) {
// Semantic action prologue.
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();

auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler38(yyparse& parser) {
// Semantic action prologue.


auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler39(yyparse& parser) {
// Semantic action prologue.
parser.tokensStack.pop_back();

// size: INTEGER
    auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler40(yyparse& parser) {
// Semantic action prologue.


auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler41(yyparse& parser) {
// Semantic action prologue.
parser.tokensStack.pop_back();

// length: INTEGER
    auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler42(yyparse& parser) {
// Semantic action prologue.
parser.valuesStack.pop_back();

// return: void
    auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler43(yyparse& parser) {
// Semantic action prologue.
parser.valuesStack.pop_back();

// return: type
    auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler44(yyparse& parser) {
// Semantic action prologue.
parser.valuesStack.pop_back();

debug("type: type_base");
    auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler45(yyparse& parser) {
// Semantic action prologue.
parser.valuesStack.pop_back();

debug("type: identifier");
    auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler46(yyparse& parser) {
// Semantic action prologue.
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();
auto _1 = POP_V();

debug("type: type[length]");
    auto __ = _1;

 // Semantic action epilogue.
PUSH_VR();

}

void _handler47(yyparse& parser) {
// Semantic action prologue.
parser.valuesStack.pop_back();

auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler48(yyparse& parser) {
// Semantic action prologue.
parser.tokensStack.pop_back();
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();

auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler49(yyparse& parser) {
// Semantic action prologue.
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();

auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler50(yyparse& parser) {
// Semantic action prologue.
parser.valuesStack.pop_back();

auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler51(yyparse& parser) {
// Semantic action prologue.
parser.tokensStack.pop_back();
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();

auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler52(yyparse& parser) {
// Semantic action prologue.
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();

auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler53(yyparse& parser) {
// Semantic action prologue.
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();

debug("type_func_decl: type_func(arg_list): return");
    auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler54(yyparse& parser) {
// Semantic action prologue.
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();

auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler55(yyparse& parser) {
// Semantic action prologue.
auto _1 = POP_V();

debug("identifier_list: identifier");
    auto __ = std::make_shared<ListNode>(_1);

 // Semantic action epilogue.
PUSH_VR();

}

void _handler56(yyparse& parser) {
// Semantic action prologue.
auto _3 = POP_V();
parser.tokensStack.pop_back();
auto _1 = POP_V();

debug("identifier_list: identiifer_list, identifier");
    as(ListNode, _1)->list.push_back(_3);
    auto __ = _1;

 // Semantic action epilogue.
PUSH_VR();

}

void _handler57(yyparse& parser) {
// Semantic action prologue.
parser.valuesStack.pop_back();

debug("arg: identifier_list");
    auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler58(yyparse& parser) {
// Semantic action prologue.
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();

debug("arg: var identifier_list");
    auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler59(yyparse& parser) {
// Semantic action prologue.
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();
auto _1 = POP_V();

debug("arg: arg: type");
    auto __ = _1;

 // Semantic action epilogue.
PUSH_VR();

}

void _handler60(yyparse& parser) {
// Semantic action prologue.
auto _1 = POP_V();

debug("arg_set: arg");
    auto __ = std::make_shared<ListNode>(_1);

 // Semantic action epilogue.
PUSH_VR();

}

void _handler61(yyparse& parser) {
// Semantic action prologue.
auto _3 = POP_V();
parser.tokensStack.pop_back();
auto _1 = POP_V();

debug("arg_set: arg_set SEMICOLON arg");
    as(ListNode, _1)->list.push_back(_3);
    auto __ = _1;

 // Semantic action epilogue.
PUSH_VR();

}

void _handler62(yyparse& parser) {
// Semantic action prologue.


debug("arg_list: empty");
    auto __ = std::make_shared<ListNode>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler63(yyparse& parser) {
// Semantic action prologue.
auto _1 = POP_V();

debug("arg_list: arg_set");
    auto __ = _1;

 // Semantic action epilogue.
PUSH_VR();

}

void _handler64(yyparse& parser) {
// Semantic action prologue.
auto _1 = POP_T();

debug("type_base: " + _1);
    auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler65(yyparse& parser) {
// Semantic action prologue.
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();
auto _1 = POP_V();

debug("type_base: type_base(size)");
    auto __ = _1
  ;

 // Semantic action epilogue.
PUSH_VR();

}

void _handler66(yyparse& parser) {
// Semantic action prologue.
auto _1 = POP_T();

debug("type_form: " + _1);
    auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler67(yyparse& parser) {
// Semantic action prologue.
auto _1 = POP_T();

debug("type_tmpl: " + _1);
    auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler68(yyparse& parser) {
// Semantic action prologue.
parser.tokensStack.pop_back();

debug("type_func: function");
    auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler69(yyparse& parser) {
// Semantic action prologue.
parser.tokensStack.pop_back();

debug("type_cons: constructor");
    auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler70(yyparse& parser) {
// Semantic action prologue.
parser.tokensStack.pop_back();

debug("void: void");
    auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler71(yyparse& parser) {
// Semantic action prologue.
parser.valuesStack.pop_back();

auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler72(yyparse& parser) {
// Semantic action prologue.
parser.valuesStack.pop_back();

auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler73(yyparse& parser) {
// Semantic action prologue.
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();

auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler74(yyparse& parser) {
// Semantic action prologue.
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();

auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler75(yyparse& parser) {
// Semantic action prologue.
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();
parser.tokensStack.pop_back();
parser.valuesStack.pop_back();

auto __ = std::make_shared<Node>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler76(yyparse& parser) {
// Semantic action prologue.


auto __ = std::make_shared<ListNode>();

 // Semantic action epilogue.
PUSH_VR();

}

void _handler77(yyparse& parser) {
// Semantic action prologue.
auto _1 = POP_V();

auto __ = _1;

 // Semantic action epilogue.
PUSH_VR();

}

void _handler78(yyparse& parser) {
// Semantic action prologue.
auto _1 = POP_V();

auto __ = std::make_shared<ListNode>(_1);

 // Semantic action epilogue.
PUSH_VR();

}

void _handler79(yyparse& parser) {
// Semantic action prologue.
auto _3 = POP_V();
parser.tokensStack.pop_back();
auto _1 = POP_V();

as(ListNode, _1)->list.push_back(_3);
    auto __ = _1;

 // Semantic action epilogue.
PUSH_VR();

}
// clang-format on

// clang-format off
std::array<Production, yyparse::PRODUCTIONS_COUNT> yyparse::productions_ = {{{-1, 1, &_handler1},
{0, 0, &_handler2},
{0, 2, &_handler3},
{1, 1, &_handler4},
{1, 1, &_handler5},
{1, 1, &_handler6},
{2, 0, &_handler7},
{2, 2, &_handler8},
{3, 2, &_handler9},
{4, 1, &_handler10},
{5, 1, &_handler11},
{5, 1, &_handler12},
{5, 1, &_handler13},
{5, 1, &_handler14},
{6, 1, &_handler15},
{7, 1, &_handler16},
{7, 3, &_handler17},
{8, 1, &_handler18},
{8, 3, &_handler19},
{9, 1, &_handler20},
{9, 3, &_handler21},
{10, 3, &_handler22},
{10, 4, &_handler23},
{11, 3, &_handler24},
{12, 1, &_handler25},
{12, 3, &_handler26},
{13, 1, &_handler27},
{13, 3, &_handler28},
{13, 4, &_handler29},
{14, 1, &_handler30},
{14, 3, &_handler31},
{15, 1, &_handler32},
{15, 3, &_handler33},
{16, 6, &_handler34},
{16, 6, &_handler35},
{16, 7, &_handler36},
{16, 7, &_handler37},
{17, 0, &_handler38},
{17, 1, &_handler39},
{18, 0, &_handler40},
{18, 1, &_handler41},
{19, 1, &_handler42},
{19, 1, &_handler43},
{20, 1, &_handler44},
{20, 1, &_handler45},
{20, 4, &_handler46},
{21, 1, &_handler47},
{21, 3, &_handler48},
{21, 4, &_handler49},
{22, 1, &_handler50},
{22, 3, &_handler51},
{22, 4, &_handler52},
{23, 6, &_handler53},
{24, 6, &_handler54},
{25, 1, &_handler55},
{25, 3, &_handler56},
{26, 1, &_handler57},
{26, 2, &_handler58},
{26, 3, &_handler59},
{27, 1, &_handler60},
{27, 3, &_handler61},
{28, 0, &_handler62},
{28, 1, &_handler63},
{29, 1, &_handler64},
{29, 4, &_handler65},
{30, 1, &_handler66},
{31, 1, &_handler67},
{32, 1, &_handler68},
{33, 1, &_handler69},
{34, 1, &_handler70},
{35, 1, &_handler71},
{35, 1, &_handler72},
{35, 4, &_handler73},
{35, 3, &_handler74},
{35, 6, &_handler75},
{36, 0, &_handler76},
{36, 1, &_handler77},
{37, 1, &_handler78},
{37, 3, &_handler79}}};
// clang-format on

// ------------------------------------------------------------------
// Parsing table.

// clang-format off
std::array<Row, yyparse::ROWS_COUNT> yyparse::table_ = {
    Row {{0, {TE::Transit, 1}}, {50, {TE::Reduce, 1}}, {51, {TE::Reduce, 1}}, {55, {TE::Reduce, 1}}, {66, {TE::Reduce, 1}}},
    Row {{1, {TE::Transit, 2}}, {10, {TE::Transit, 3}}, {11, {TE::Transit, 4}}, {16, {TE::Transit, 5}}, {50, {TE::Shift, 6}}, {51, {TE::Shift, 7}}, {55, {TE::Shift, 8}}, {66, {TE::Accept, 0}}},
    Row {{50, {TE::Reduce, 2}}, {51, {TE::Reduce, 2}}, {55, {TE::Reduce, 2}}, {66, {TE::Reduce, 2}}},
    Row {{50, {TE::Reduce, 3}}, {51, {TE::Reduce, 3}}, {55, {TE::Reduce, 3}}, {66, {TE::Reduce, 3}}},
    Row {{50, {TE::Reduce, 4}}, {51, {TE::Reduce, 4}}, {55, {TE::Reduce, 4}}, {66, {TE::Reduce, 4}}},
    Row {{50, {TE::Reduce, 5}}, {51, {TE::Reduce, 5}}, {55, {TE::Reduce, 5}}, {66, {TE::Reduce, 5}}},
    Row {{6, {TE::Transit, 9}}, {7, {TE::Transit, 10}}, {43, {TE::Shift, 11}}},
    Row {{6, {TE::Transit, 19}}, {7, {TE::Transit, 18}}, {8, {TE::Transit, 17}}, {12, {TE::Transit, 15}}, {13, {TE::Transit, 16}}, {43, {TE::Shift, 11}}},
    Row {{6, {TE::Transit, 38}}, {43, {TE::Shift, 11}}},
    Row {{38, {TE::Shift, 12}}, {44, {TE::Reduce, 15}}},
    Row {{44, {TE::Shift, 13}}},
    Row {{38, {TE::Reduce, 14}}, {44, {TE::Reduce, 14}}, {48, {TE::Reduce, 14}}, {49, {TE::Reduce, 14}}, {50, {TE::Reduce, 14}}, {51, {TE::Reduce, 14}}, {52, {TE::Reduce, 14}}, {53, {TE::Reduce, 14}}, {54, {TE::Reduce, 14}}, {55, {TE::Reduce, 14}}, {56, {TE::Reduce, 14}}, {57, {TE::Reduce, 14}}, {58, {TE::Reduce, 14}}, {60, {TE::Reduce, 14}}, {61, {TE::Reduce, 14}}, {66, {TE::Reduce, 14}}},
    Row {{50, {TE::Reduce, 21}}, {51, {TE::Reduce, 21}}, {55, {TE::Reduce, 21}}, {66, {TE::Reduce, 21}}},
    Row {{6, {TE::Transit, 14}}, {43, {TE::Shift, 11}}},
    Row {{44, {TE::Reduce, 16}}, {50, {TE::Reduce, 22}}, {51, {TE::Reduce, 22}}, {55, {TE::Reduce, 22}}, {66, {TE::Reduce, 22}}},
    Row {{38, {TE::Shift, 20}}, {49, {TE::Shift, 21}}},
    Row {{38, {TE::Reduce, 24}}, {49, {TE::Reduce, 24}}},
    Row {{38, {TE::Reduce, 26}}, {49, {TE::Reduce, 26}}, {52, {TE::Shift, 23}}},
    Row {{44, {TE::Shift, 27}}, {48, {TE::Shift, 26}}, {53, {TE::Shift, 25}}},
    Row {{38, {TE::Reduce, 17}}, {44, {TE::Reduce, 15}}, {48, {TE::Reduce, 15}}, {49, {TE::Reduce, 17}}, {52, {TE::Reduce, 17}}, {53, {TE::Reduce, 15}}, {54, {TE::Reduce, 17}}},
    Row {{50, {TE::Reduce, 23}}, {51, {TE::Reduce, 23}}, {55, {TE::Reduce, 23}}, {66, {TE::Reduce, 23}}},
    Row {{6, {TE::Transit, 19}}, {7, {TE::Transit, 18}}, {8, {TE::Transit, 17}}, {13, {TE::Transit, 22}}, {43, {TE::Shift, 11}}},
    Row {{38, {TE::Reduce, 25}}, {49, {TE::Reduce, 25}}},
    Row {{6, {TE::Transit, 24}}, {43, {TE::Shift, 11}}},
    Row {{38, {TE::Reduce, 27}}, {49, {TE::Reduce, 27}}},
    Row {{6, {TE::Transit, 30}}, {14, {TE::Transit, 28}}, {15, {TE::Transit, 29}}, {43, {TE::Shift, 11}}},
    Row {{6, {TE::Transit, 36}}, {43, {TE::Shift, 11}}},
    Row {{6, {TE::Transit, 37}}, {43, {TE::Shift, 11}}},
    Row {{49, {TE::Shift, 32}}, {54, {TE::Shift, 31}}},
    Row {{49, {TE::Reduce, 29}}, {54, {TE::Reduce, 29}}},
    Row {{49, {TE::Reduce, 31}}, {52, {TE::Shift, 34}}, {54, {TE::Reduce, 31}}},
    Row {{38, {TE::Reduce, 28}}, {49, {TE::Reduce, 28}}},
    Row {{6, {TE::Transit, 30}}, {15, {TE::Transit, 33}}, {43, {TE::Shift, 11}}},
    Row {{49, {TE::Reduce, 30}}, {54, {TE::Reduce, 30}}},
    Row {{6, {TE::Transit, 35}}, {43, {TE::Shift, 11}}},
    Row {{49, {TE::Reduce, 32}}, {54, {TE::Reduce, 32}}},
    Row {{38, {TE::Reduce, 18}}, {49, {TE::Reduce, 18}}, {52, {TE::Reduce, 18}}, {54, {TE::Reduce, 18}}},
    Row {{38, {TE::Reduce, 16}}, {44, {TE::Reduce, 16}}, {48, {TE::Reduce, 16}}, {49, {TE::Reduce, 16}}, {53, {TE::Reduce, 16}}, {54, {TE::Reduce, 16}}, {60, {TE::Reduce, 16}}, {61, {TE::Reduce, 16}}},
    Row {{56, {TE::Shift, 39}}},
    Row {{21, {TE::Transit, 40}}, {22, {TE::Transit, 42}}, {23, {TE::Transit, 41}}, {30, {TE::Transit, 43}}, {31, {TE::Transit, 47}}, {32, {TE::Transit, 45}}, {46, {TE::Shift, 44}}, {47, {TE::Shift, 48}}, {63, {TE::Shift, 46}}},
    Row {{57, {TE::Shift, 49}}},
    Row {{57, {TE::Shift, 73}}, {58, {TE::Shift, 74}}},
    Row {{58, {TE::Shift, 79}}},
    Row {{53, {TE::Shift, 82}}, {57, {TE::Reduce, 46}}},
    Row {{53, {TE::Reduce, 65}}, {57, {TE::Reduce, 65}}},
    Row {{53, {TE::Shift, 90}}},
    Row {{53, {TE::Reduce, 67}}},
    Row {{53, {TE::Shift, 121}}, {58, {TE::Reduce, 49}}},
    Row {{53, {TE::Reduce, 66}}, {58, {TE::Reduce, 66}}},
    Row {{3, {TE::Transit, 50}}, {4, {TE::Transit, 52}}, {5, {TE::Transit, 54}}, {6, {TE::Transit, 59}}, {7, {TE::Transit, 53}}, {35, {TE::Transit, 51}}, {39, {TE::Shift, 55}}, {40, {TE::Shift, 56}}, {41, {TE::Shift, 57}}, {42, {TE::Shift, 58}}, {43, {TE::Shift, 11}}},
    Row {{50, {TE::Reduce, 33}}, {51, {TE::Reduce, 33}}, {55, {TE::Reduce, 33}}, {66, {TE::Reduce, 33}}},
    Row {{38, {TE::Shift, 60}}, {48, {TE::Shift, 62}}, {60, {TE::Shift, 61}}},
    Row {{38, {TE::Reduce, 70}}, {48, {TE::Reduce, 70}}, {49, {TE::Reduce, 70}}, {54, {TE::Reduce, 70}}, {60, {TE::Reduce, 70}}, {61, {TE::Reduce, 70}}},
    Row {{38, {TE::Reduce, 71}}, {44, {TE::Shift, 27}}, {48, {TE::Reduce, 71}}, {49, {TE::Reduce, 71}}, {54, {TE::Reduce, 71}}, {60, {TE::Reduce, 71}}, {61, {TE::Reduce, 71}}},
    Row {{38, {TE::Reduce, 9}}, {48, {TE::Reduce, 9}}, {49, {TE::Reduce, 9}}, {54, {TE::Reduce, 9}}, {60, {TE::Reduce, 9}}, {61, {TE::Reduce, 9}}},
    Row {{38, {TE::Reduce, 10}}, {48, {TE::Reduce, 10}}, {49, {TE::Reduce, 10}}, {54, {TE::Reduce, 10}}, {60, {TE::Reduce, 10}}, {61, {TE::Reduce, 10}}},
    Row {{38, {TE::Reduce, 11}}, {48, {TE::Reduce, 11}}, {49, {TE::Reduce, 11}}, {54, {TE::Reduce, 11}}, {60, {TE::Reduce, 11}}, {61, {TE::Reduce, 11}}},
    Row {{38, {TE::Reduce, 12}}, {48, {TE::Reduce, 12}}, {49, {TE::Reduce, 12}}, {54, {TE::Reduce, 12}}, {60, {TE::Reduce, 12}}, {61, {TE::Reduce, 12}}},
    Row {{38, {TE::Reduce, 13}}, {48, {TE::Reduce, 13}}, {49, {TE::Reduce, 13}}, {54, {TE::Reduce, 13}}, {60, {TE::Reduce, 13}}, {61, {TE::Reduce, 13}}},
    Row {{38, {TE::Reduce, 15}}, {44, {TE::Reduce, 15}}, {48, {TE::Reduce, 15}}, {49, {TE::Reduce, 15}}, {54, {TE::Reduce, 15}}, {60, {TE::Reduce, 15}}, {61, {TE::Reduce, 15}}},
    Row {{39, {TE::Reduce, 8}}, {40, {TE::Reduce, 8}}, {41, {TE::Reduce, 8}}, {42, {TE::Reduce, 8}}, {43, {TE::Reduce, 8}}, {50, {TE::Reduce, 8}}, {51, {TE::Reduce, 8}}, {55, {TE::Reduce, 8}}, {59, {TE::Reduce, 8}}, {66, {TE::Reduce, 8}}},
    Row {{4, {TE::Transit, 52}}, {5, {TE::Transit, 54}}, {6, {TE::Transit, 59}}, {7, {TE::Transit, 53}}, {35, {TE::Transit, 63}}, {39, {TE::Shift, 55}}, {40, {TE::Shift, 56}}, {41, {TE::Shift, 57}}, {42, {TE::Shift, 58}}, {43, {TE::Shift, 11}}},
    Row {{6, {TE::Transit, 65}}, {43, {TE::Shift, 11}}},
    Row {{48, {TE::Shift, 62}}, {60, {TE::Shift, 61}}, {61, {TE::Shift, 64}}},
    Row {{38, {TE::Reduce, 72}}, {48, {TE::Reduce, 72}}, {49, {TE::Reduce, 72}}, {54, {TE::Reduce, 72}}, {60, {TE::Reduce, 72}}, {61, {TE::Reduce, 72}}},
    Row {{38, {TE::Reduce, 73}}, {48, {TE::Reduce, 73}}, {49, {TE::Reduce, 73}}, {53, {TE::Shift, 66}}, {54, {TE::Reduce, 73}}, {60, {TE::Reduce, 73}}, {61, {TE::Reduce, 73}}},
    Row {{4, {TE::Transit, 52}}, {5, {TE::Transit, 54}}, {6, {TE::Transit, 59}}, {7, {TE::Transit, 53}}, {35, {TE::Transit, 69}}, {36, {TE::Transit, 67}}, {37, {TE::Transit, 68}}, {39, {TE::Shift, 55}}, {40, {TE::Shift, 56}}, {41, {TE::Shift, 57}}, {42, {TE::Shift, 58}}, {43, {TE::Shift, 11}}, {54, {TE::Reduce, 75}}},
    Row {{54, {TE::Shift, 70}}},
    Row {{49, {TE::Shift, 71}}, {54, {TE::Reduce, 76}}},
    Row {{48, {TE::Shift, 62}}, {49, {TE::Reduce, 77}}, {54, {TE::Reduce, 77}}, {60, {TE::Shift, 61}}},
    Row {{38, {TE::Reduce, 74}}, {48, {TE::Reduce, 74}}, {49, {TE::Reduce, 74}}, {54, {TE::Reduce, 74}}, {60, {TE::Reduce, 74}}, {61, {TE::Reduce, 74}}},
    Row {{4, {TE::Transit, 52}}, {5, {TE::Transit, 54}}, {6, {TE::Transit, 59}}, {7, {TE::Transit, 53}}, {35, {TE::Transit, 72}}, {39, {TE::Shift, 55}}, {40, {TE::Shift, 56}}, {41, {TE::Shift, 57}}, {42, {TE::Shift, 58}}, {43, {TE::Shift, 11}}},
    Row {{48, {TE::Shift, 62}}, {49, {TE::Reduce, 78}}, {54, {TE::Reduce, 78}}, {60, {TE::Shift, 61}}},
    Row {{3, {TE::Transit, 75}}, {4, {TE::Transit, 52}}, {5, {TE::Transit, 54}}, {6, {TE::Transit, 59}}, {7, {TE::Transit, 53}}, {35, {TE::Transit, 51}}, {39, {TE::Shift, 55}}, {40, {TE::Shift, 56}}, {41, {TE::Shift, 57}}, {42, {TE::Shift, 58}}, {43, {TE::Shift, 11}}},
    Row {{2, {TE::Transit, 76}}, {39, {TE::Reduce, 6}}, {40, {TE::Reduce, 6}}, {41, {TE::Reduce, 6}}, {42, {TE::Reduce, 6}}, {43, {TE::Reduce, 6}}, {59, {TE::Reduce, 6}}},
    Row {{50, {TE::Reduce, 34}}, {51, {TE::Reduce, 34}}, {55, {TE::Reduce, 34}}, {66, {TE::Reduce, 34}}},
    Row {{3, {TE::Transit, 78}}, {4, {TE::Transit, 52}}, {5, {TE::Transit, 54}}, {6, {TE::Transit, 59}}, {7, {TE::Transit, 53}}, {35, {TE::Transit, 51}}, {39, {TE::Shift, 55}}, {40, {TE::Shift, 56}}, {41, {TE::Shift, 57}}, {42, {TE::Shift, 58}}, {43, {TE::Shift, 11}}, {59, {TE::Shift, 77}}},
    Row {{50, {TE::Reduce, 35}}, {51, {TE::Reduce, 35}}, {55, {TE::Reduce, 35}}, {66, {TE::Reduce, 35}}},
    Row {{39, {TE::Reduce, 7}}, {40, {TE::Reduce, 7}}, {41, {TE::Reduce, 7}}, {42, {TE::Reduce, 7}}, {43, {TE::Reduce, 7}}, {59, {TE::Reduce, 7}}},
    Row {{2, {TE::Transit, 80}}, {39, {TE::Reduce, 6}}, {40, {TE::Reduce, 6}}, {41, {TE::Reduce, 6}}, {42, {TE::Reduce, 6}}, {43, {TE::Reduce, 6}}, {59, {TE::Reduce, 6}}},
    Row {{3, {TE::Transit, 78}}, {4, {TE::Transit, 52}}, {5, {TE::Transit, 54}}, {6, {TE::Transit, 59}}, {7, {TE::Transit, 53}}, {35, {TE::Transit, 51}}, {39, {TE::Shift, 55}}, {40, {TE::Shift, 56}}, {41, {TE::Shift, 57}}, {42, {TE::Shift, 58}}, {43, {TE::Shift, 11}}, {59, {TE::Shift, 81}}},
    Row {{50, {TE::Reduce, 36}}, {51, {TE::Reduce, 36}}, {55, {TE::Reduce, 36}}, {66, {TE::Reduce, 36}}},
    Row {{6, {TE::Transit, 19}}, {7, {TE::Transit, 86}}, {8, {TE::Transit, 85}}, {9, {TE::Transit, 84}}, {43, {TE::Shift, 11}}, {54, {TE::Shift, 83}}},
    Row {{57, {TE::Reduce, 47}}},
    Row {{49, {TE::Shift, 88}}, {54, {TE::Shift, 87}}},
    Row {{49, {TE::Reduce, 19}}, {54, {TE::Reduce, 19}}},
    Row {{44, {TE::Shift, 27}}, {48, {TE::Shift, 26}}},
    Row {{57, {TE::Reduce, 48}}},
    Row {{6, {TE::Transit, 19}}, {7, {TE::Transit, 86}}, {8, {TE::Transit, 89}}, {43, {TE::Shift, 11}}},
    Row {{49, {TE::Reduce, 20}}, {54, {TE::Reduce, 20}}},
    Row {{6, {TE::Transit, 96}}, {25, {TE::Transit, 94}}, {26, {TE::Transit, 93}}, {27, {TE::Transit, 92}}, {28, {TE::Transit, 91}}, {43, {TE::Shift, 11}}, {54, {TE::Reduce, 61}}, {62, {TE::Shift, 95}}},
    Row {{54, {TE::Shift, 97}}},
    Row {{38, {TE::Shift, 114}}, {54, {TE::Reduce, 62}}},
    Row {{38, {TE::Reduce, 59}}, {54, {TE::Reduce, 59}}, {56, {TE::Shift, 116}}},
    Row {{38, {TE::Reduce, 56}}, {49, {TE::Shift, 118}}, {54, {TE::Reduce, 56}}, {56, {TE::Reduce, 56}}},
    Row {{6, {TE::Transit, 96}}, {25, {TE::Transit, 120}}, {43, {TE::Shift, 11}}},
    Row {{38, {TE::Reduce, 54}}, {49, {TE::Reduce, 54}}, {54, {TE::Reduce, 54}}, {56, {TE::Reduce, 54}}},
    Row {{56, {TE::Shift, 98}}},
    Row {{6, {TE::Transit, 104}}, {19, {TE::Transit, 99}}, {20, {TE::Transit, 101}}, {29, {TE::Transit, 103}}, {34, {TE::Transit, 100}}, {43, {TE::Shift, 11}}, {45, {TE::Shift, 105}}, {65, {TE::Shift, 102}}},
    Row {{57, {TE::Reduce, 52}}, {58, {TE::Reduce, 52}}},
    Row {{57, {TE::Reduce, 41}}, {58, {TE::Reduce, 41}}},
    Row {{57, {TE::Reduce, 42}}, {58, {TE::Reduce, 42}}, {60, {TE::Shift, 106}}},
    Row {{57, {TE::Reduce, 69}}, {58, {TE::Reduce, 69}}},
    Row {{38, {TE::Reduce, 43}}, {53, {TE::Shift, 110}}, {54, {TE::Reduce, 43}}, {56, {TE::Reduce, 43}}, {57, {TE::Reduce, 43}}, {58, {TE::Reduce, 43}}, {60, {TE::Reduce, 43}}},
    Row {{38, {TE::Reduce, 44}}, {54, {TE::Reduce, 44}}, {56, {TE::Reduce, 44}}, {57, {TE::Reduce, 44}}, {58, {TE::Reduce, 44}}, {60, {TE::Reduce, 44}}},
    Row {{38, {TE::Reduce, 63}}, {53, {TE::Reduce, 63}}, {54, {TE::Reduce, 63}}, {56, {TE::Reduce, 63}}, {57, {TE::Reduce, 63}}, {58, {TE::Reduce, 63}}, {60, {TE::Reduce, 63}}},
    Row {{18, {TE::Transit, 107}}, {40, {TE::Shift, 108}}, {61, {TE::Reduce, 39}}},
    Row {{61, {TE::Shift, 109}}},
    Row {{61, {TE::Reduce, 40}}},
    Row {{38, {TE::Reduce, 45}}, {54, {TE::Reduce, 45}}, {56, {TE::Reduce, 45}}, {57, {TE::Reduce, 45}}, {58, {TE::Reduce, 45}}, {60, {TE::Reduce, 45}}},
    Row {{17, {TE::Transit, 111}}, {40, {TE::Shift, 112}}, {54, {TE::Reduce, 37}}},
    Row {{54, {TE::Shift, 113}}},
    Row {{54, {TE::Reduce, 38}}},
    Row {{38, {TE::Reduce, 64}}, {53, {TE::Reduce, 64}}, {54, {TE::Reduce, 64}}, {56, {TE::Reduce, 64}}, {57, {TE::Reduce, 64}}, {58, {TE::Reduce, 64}}, {60, {TE::Reduce, 64}}},
    Row {{6, {TE::Transit, 96}}, {25, {TE::Transit, 94}}, {26, {TE::Transit, 115}}, {43, {TE::Shift, 11}}, {62, {TE::Shift, 95}}},
    Row {{38, {TE::Reduce, 60}}, {54, {TE::Reduce, 60}}, {56, {TE::Shift, 116}}},
    Row {{6, {TE::Transit, 104}}, {20, {TE::Transit, 117}}, {29, {TE::Transit, 103}}, {43, {TE::Shift, 11}}, {45, {TE::Shift, 105}}},
    Row {{38, {TE::Reduce, 58}}, {54, {TE::Reduce, 58}}, {56, {TE::Reduce, 58}}, {60, {TE::Shift, 106}}},
    Row {{6, {TE::Transit, 119}}, {43, {TE::Shift, 11}}},
    Row {{38, {TE::Reduce, 55}}, {49, {TE::Reduce, 55}}, {54, {TE::Reduce, 55}}, {56, {TE::Reduce, 55}}},
    Row {{38, {TE::Reduce, 57}}, {49, {TE::Shift, 118}}, {54, {TE::Reduce, 57}}, {56, {TE::Reduce, 57}}},
    Row {{6, {TE::Transit, 19}}, {7, {TE::Transit, 86}}, {8, {TE::Transit, 85}}, {9, {TE::Transit, 123}}, {43, {TE::Shift, 11}}, {54, {TE::Shift, 122}}},
    Row {{58, {TE::Reduce, 50}}},
    Row {{49, {TE::Shift, 88}}, {54, {TE::Shift, 124}}},
    Row {{58, {TE::Reduce, 51}}}
};
// clang-format on

}  // namespace syntax

#endif